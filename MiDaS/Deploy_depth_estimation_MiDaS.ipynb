{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8337ee31",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b33f2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import boto3\n",
    "import os\n",
    "import sagemaker\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15c12bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.predictor import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc57472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import strftime,gmtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0f999e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af86bf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "sns_client = boto3.client('sns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "572810a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role, Session, image_uris\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8bffc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.session.Session()\n",
    "sm_runtime = boto_session.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523dedbf",
   "metadata": {},
   "source": [
    "## Load model from Torch Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_type= 'DPT_Large'\n",
    "\n",
    "#midas= torch.hub.load(\"intel-isl/MiDaS\", model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a80ec18",
   "metadata": {},
   "source": [
    "### Create model archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeb79588",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_archive_name = 'MiDaS.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39bb12a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pth\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tar -cvzf {model_archive_name} model.pth code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a8ad3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model uploaded to: s3://sagemaker-ca-central-1-333752261573/MiDaS_model/MiDaS.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# model package tarball (model artifact + inference code)\n",
    "model_url = sess.upload_data(path=model_archive_name, key_prefix='MiDaS_model')\n",
    "print('model uploaded to: {}'.format(model_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4048d665",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_url= 's3://sagemaker-ca-central-1-333752261573/MiDaS_model/MiDaS.tar.gz'\n",
    "#print('model uploaded to: {}'.format(model_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9883f69",
   "metadata": {},
   "source": [
    "### Create async model archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b4d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_archive_name = 'MiDaS_async.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27d81687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pth\n",
      "code/\n",
      "code/requirements.txt\n",
      "code/inference.py\n",
      "code/.ipynb_checkpoints/\n",
      "code/midas/\n",
      "code/midas/transforms.py\n",
      "code/midas/vit.py\n",
      "code/midas/midas_net.py\n",
      "code/midas/midas_net_custom.py\n",
      "code/midas/blocks.py\n",
      "code/midas/dpt_depth.py\n",
      "code/midas/base_model.py\n"
     ]
    }
   ],
   "source": [
    "!tar -cvzf {model_archive_name} model.pth code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fdc0fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model uploaded to: s3://sagemaker-ca-central-1-333752261573/MiDaS_model/MiDaS_async.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# model package tarball (model artifact + inference code)\n",
    "model_url = sess.upload_data(path=model_archive_name, key_prefix='MiDaS_model')\n",
    "print('model uploaded to: {}'.format(model_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07229ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model uploaded to: s3://sagemaker-ca-central-1-333752261573/MiDaS_model/MiDaS_async.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_url= 's3://sagemaker-ca-central-1-333752261573/MiDaS_model/MiDaS_async.tar.gz'\n",
    "print('model uploaded to: {}'.format(model_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c7bfc",
   "metadata": {},
   "source": [
    "### Create model and test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc94223f",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_version = '1.7.1'\n",
    "py_version = 'py36'\n",
    "env= {\n",
    "            'TS_MAX_REQUEST_SIZE': '100000000', #default max request size is 6 Mb for torchserve, need to update it to support the 70 mb input payload\n",
    "            'TS_MAX_RESPONSE_SIZE': '100000000',\n",
    "            'TS_DEFAULT_RESPONSE_TIMEOUT': '1000'\n",
    "        }\n",
    "\n",
    "sm_model = PyTorchModel(model_data=model_url,\n",
    "                               framework_version=framework_version,\n",
    "                               role=role,\n",
    "                               sagemaker_session=sess,\n",
    "                               entry_point='inference.py',\n",
    "                               source_dir= 'code-realtime',\n",
    "                               env=env,\n",
    "                               py_version=py_version\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddd9dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "instance_type = 'ml.g4dn.xlarge'\n",
    "uncompiled_predictor = sm_model.deploy(initial_instance_count=1, instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f426f",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09db8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import requests\n",
    "client = boto3.client('sagemaker-runtime', region_name=region)\n",
    "content_type = 'application/x-image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71a1d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sample 1\n",
    "sample_img_url = \"https://github.com/ultralytics/yolov5/raw/master/data/images/zidane.jpg\"\n",
    "body = requests.get(sample_img_url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "8593f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test sample 2\n",
    "path= 'test_data/frame54.jpg'\n",
    "img = cv2.imread(path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "body = io.open(path, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "31a3d2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2479.1440963745117\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "rv = client.invoke_endpoint(EndpointName=uncompiled_predictor.endpoint_name, Body=body, ContentType=content_type)\n",
    "t1 = time.time()\n",
    "\n",
    "time_elapsed = (t1-t0)*1000\n",
    "print(time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "317a0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions= json.loads(rv['Body'].read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "d5fa81ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "fb195f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_arr = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "cad573f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1920)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b97a3",
   "metadata": {},
   "source": [
    "# Measure invocation time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "2faa200d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2742.748975753784\n",
      "2541.4199829101562\n",
      "2556.5035343170166\n",
      "2503.575086593628\n",
      "2598.672389984131\n",
      "2535.305976867676\n",
      "2511.230230331421\n",
      "2836.294412612915\n",
      "2538.0184650421143\n",
      "2510.0882053375244\n"
     ]
    }
   ],
   "source": [
    "inferenceTime_list=[]\n",
    "for i in range(10):\n",
    "    body = io.open(path, 'rb')\n",
    "    t0 = time.time()\n",
    "    rv = client.invoke_endpoint(EndpointName=uncompiled_predictor.endpoint_name, Body=body, ContentType=content_type)\n",
    "    t1 = time.time()\n",
    "\n",
    "    time_elapsed = (t1-t0)*1000\n",
    "    inferenceTime_list.append(time_elapsed)\n",
    "    print(time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "fa6ed1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2587.3857259750366"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(inferenceTime_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a715b",
   "metadata": {},
   "source": [
    "# Async endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6830395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n",
    "\n",
    "bucket= 'gulogulo-inference-results'\n",
    "\n",
    "async_config = AsyncInferenceConfig(\n",
    "                output_path= f\"s3://{bucket}/output\",\n",
    "                max_concurrent_invocations_per_instance=2,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dee68b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_version = '1.7.1'\n",
    "py_version = 'py36'\n",
    "env= {\n",
    "            'TS_MAX_REQUEST_SIZE': '100000000', #default max request size is 6 Mb for torchserve, need to update it to support the 70 mb input payload\n",
    "            'TS_MAX_RESPONSE_SIZE': '2000000000',\n",
    "            'TS_DEFAULT_RESPONSE_TIMEOUT': '1000'\n",
    "        }\n",
    "\n",
    "sm_model = PyTorchModel(model_data=model_url,\n",
    "                               framework_version=framework_version,\n",
    "                               role=role,\n",
    "                               sagemaker_session=sess,\n",
    "                               entry_point='inference.py',\n",
    "                               source_dir= 'code-async',\n",
    "                               env=env,\n",
    "                               py_version=py_version\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738bd586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "instance_type = 'ml.g4dn.xlarge'\n",
    "async_uncompiled_predictor = sm_model.deploy(async_inference_config=async_config,\n",
    "                                       initial_instance_count=1,\n",
    "                                       instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fecb441",
   "metadata": {},
   "source": [
    "# Test endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "381786d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name= ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6a3d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1_s3_location= ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2796515a",
   "metadata": {},
   "source": [
    "### Invoke async endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ceae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_runtime.invoke_endpoint_async(\n",
    "    EndpointName=endpoint_name, \n",
    "    InputLocation=input_1_s3_location)\n",
    "output_location = response['OutputLocation']\n",
    "print(f\"OutputLocation: {output_location}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
